{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "######### Naive Bayes######\n",
      "Training :: Naive Bayes Classifier...\n",
      "Training of Naive Bayes Classifier is completed...\n",
      "Recorded Training time (in seconds) = 5.65384316444397\n",
      "Testing :: Naive Bayes Classifier...\n",
      "Number of tests performed = 1113\n",
      "Correct labels identified = 823\n",
      "Naive Bayes Classifier's accuracy = 0.7394429469901168\n",
      "Recorded Testing time (in seconds) = 99.63257193565369\n",
      "######### Rocchio ########\n",
      "Training :: Rocchio Classifier...\n",
      "Training Rocchio Classifier completed...\n",
      "Recorded Training time (in seconds) = 6.750981569290161\n",
      "Testing :: Rocchio Classifier...\n",
      "Number of tests performed = 1113\n",
      "Correct labels identified = 758\n",
      "Rocchio Classifier accuracy = 0.6810422282120395\n",
      "Recorded Testing time (in seconds) = 12.081143140792847\n",
      "######### KNN ########\n",
      "Training :: K-Nearest Neighbor Classifier...\n",
      "Training K-Nearest Neighbor Classifier completed...\n",
      "Recorded Training time (in seconds) = 7.516926527023315\n",
      "Testing :: K-Nearest Neighbor Classifier...\n",
      "Number of tests performed = 1113\n",
      "Correct labels identified = 823\n",
      "K-Nearest Neighbor Classifier accuracy = 0.7394429469901168\n",
      " Recorded Testing time (in seconds): 87.7792854309082\n"
     ]
    }
   ],
   "source": [
    "##Importing Libraries\n",
    "import os\n",
    "import json\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from textblob.classifiers import DecisionTreeClassifier\n",
    "from textblob.classifiers import NLTKClassifier\n",
    "import time\n",
    "import nltk.classify\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "import re\n",
    "from nltk.metrics.scores import (precision, recall)\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "##Classifier classes\n",
    "class SVMClassifier(NLTKClassifier):\n",
    "    nltk_class = nltk.classify.SklearnClassifier(LinearSVC())\n",
    "\n",
    "class RocchioClassifier(NLTKClassifier):\n",
    "    nltk_class = nltk.classify.SklearnClassifier(NearestCentroid())\n",
    "\n",
    "class KNNClassifier(NLTKClassifier): \n",
    "    nltk_class = nltk.classify.SklearnClassifier(KNeighborsClassifier())\n",
    "\n",
    "##################\n",
    "##directory\n",
    "def files_from_directory(directory): #Lists all file paths from given directory\n",
    "    ret_val_direc = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.txt'):\n",
    "            ret_val_direc.append(str(directory) + \"/\" + str(file))\n",
    "    return ret_val_direc\n",
    "\n",
    "#########################\n",
    "##Defintions to read files\n",
    "def read_file(path):         #read linewise all files\n",
    "    f = open(path, 'r')      #open files from path in read mode\n",
    "    read = f.readlines()     #readlines\n",
    "    ret_val_lines = []       #linedata\n",
    "    for line in read:\n",
    "        if line.startswith(\"#\"):      #ommiting #edlines\n",
    "            pass\n",
    "        else:\n",
    "            ret_val_lines.append(line)     #append line data in ret_val_lines\n",
    "    return ret_val_lines                   #return ret_val_lines\n",
    "\n",
    "\n",
    "#######################\n",
    "#Processiong read lines- category and sentence\n",
    "def process_lines(line):                       #Returns sentence category and sentence of given line\n",
    "\n",
    "    if \"\\t\" in line:                               ##if category and sentence seperated with \\t\n",
    "        splits = line.split(\"\\t\")                  #split\n",
    "        sen_category = splits[0]                   #first split in category\n",
    "        sentence = splits[1].lower()               #next split in sentence\n",
    "        \n",
    "        for sw in stopwords:                        #stop words removal\n",
    "            sentence = sentence.replace(sw, \"\")     #replcae  \n",
    "        pattern = re.compile(\"[^\\w']\")              #recomipling sentences\n",
    "        sentence = pattern.sub(' ', sentence)       #remove spaces \n",
    "        sentence = re.sub(' +', ' ', sentence)      #remove  + before sentence\n",
    "        return sen_category, sentence               #return recompiled sentence\n",
    "    \n",
    "    else:                                          ##if category and sentence split with space\n",
    "        splits = line.split(\" \")                    #split first\n",
    "        sen_category = splits[0]                      #first space split in category\n",
    "        sentence = line[len(sen_category)+1:].lower()      #len of category+1 is put in sentence- lower case\n",
    "       \n",
    "        for sw in stopwords:                        #stop words removal\n",
    "            sentence = sentence.replace(sw, \"\")\n",
    "        pattern = re.compile(\"[^\\w']\")              #recomplie sentence\n",
    "        sentence = pattern.sub(' ', sentence)       #remove spcae in sentence\n",
    "        sentence = re.sub(' +', ' ', sentence)      #remove + and spcae before sentence\n",
    "        return sen_category, sentence               #return compiled sentence\n",
    "\n",
    "###############################\n",
    "##Writing training data in json file\n",
    "def create_json_file(input_folder, destination_file):\n",
    "    tr_folder = files_from_directory(input_folder)\n",
    "    all_in_json = []     \n",
    "    \n",
    "    for file in tr_folder:                  #accessing input training files\n",
    "        lines = read_file(file)             #reading files\n",
    "        for line in lines:                     \n",
    "            c, s = process_lines(line)       #getting line category and sentence\n",
    "            if s.endswith('\\n'):            #if sentence ends with \\n \n",
    "                s = s[:-1]                  #sentence before \\n\n",
    "            json_data = {                   #json data\n",
    "                'text': s,                  #text as s\n",
    "                'label': c                  #label as c\n",
    "            }\n",
    "            all_in_json.append(json_data)    #append data\n",
    "\n",
    "    with open(destination_file, \"w\") as outfile:    #write output file\n",
    "        json.dump(all_in_json, outfile)\n",
    "\n",
    "\n",
    "##Mapping each sentence to its category\n",
    "def prepare_test_data(input_folder):\n",
    "    \"\"\"Maps each sentence to it's category\"\"\"\n",
    "\n",
    "    test_folder = files_from_directory(input_folder)\n",
    "    t_sentences = []                                #test sentences\n",
    "    t_categories = []                               #test categories\n",
    "    for file in test_folder:                        \n",
    "        lines = read_file(file)\n",
    "        for line in lines:\n",
    "            c, s = process_lines(line)\n",
    "            if s.endswith('\\n'):\n",
    "                s = s[:-1]\n",
    "            t_sentences.append(s)\n",
    "            t_categories.append(c)\n",
    "    return t_categories, t_sentences                #return test categories and test sentences\n",
    "\n",
    "##Main\n",
    "\n",
    "#######################\n",
    "##Loading stopword file\n",
    "input_stopwords = read_file(\"C:/Users/HP/Desktop/word_lists/stopwords.txt\")\n",
    "stopwords = []\n",
    "for word in input_stopwords:\n",
    "    if word.endswith('\\n'):             #extracting stopwords\n",
    "        word = word[:-1]\n",
    "        stopwords.append(word)\n",
    "\n",
    "        \n",
    "#########################\n",
    "##Training and test data\n",
    "\n",
    "create_json_file(\"training_set\", \"training.json\")\n",
    "categories, sentences = prepare_test_data(\"test_set\")\n",
    "\n",
    "\n",
    "###################################\n",
    "##Naive Bayes Classifier\n",
    "print(\"######### Naive Bayes######\")\n",
    "\n",
    "##Training Naive Bayes\n",
    "print(\"Training :: Naive Bayes Classifier...\")\n",
    "start_nbc = time.time()                                #start time\n",
    "\n",
    "with open('training.json', 'r') as training:\n",
    "    nbc = NaiveBayesClassifier(training, format = \"json\")        #pass training data to NaiveBayesClassifier\n",
    "    \n",
    "stop_nbc = time.time()\n",
    "print(\"Training of Naive Bayes Classifier is completed...\")\n",
    "\n",
    "elapsed_time = stop_nbc - start_nbc\n",
    "print(\"Recorded Training time (in seconds) = \" + str(elapsed_time))\n",
    "\n",
    "##Testing Naive Bayes\n",
    "print(\"Testing :: Naive Bayes Classifier...\")                    \n",
    "correct_predict = 0\n",
    "start_nbc = time.time()\n",
    "\n",
    "for i in range(0, len(sentences)):\n",
    "    category = str(nbc.classify(sentences[i])).lower()\n",
    "    expected = str(categories[i]).lower()\n",
    "    if category == expected:\n",
    "        correct_predict += 1\n",
    "        \n",
    "stop_nbc = time.time()\n",
    "elapsed_time = stop_nbc - start_nbc\n",
    "\n",
    "print(\"Number of tests performed = \" + str(len(sentences)))\n",
    "print(\"Correct labels identified = \" + str(correct_predict))\n",
    "\n",
    "accuracy = correct_predict / len(sentences)                      #checking accuracy\n",
    "print(\"Naive Bayes Classifier's accuracy = \" + str(accuracy))\n",
    "print(\"Recorded Testing time (in seconds) = \" + str(elapsed_time))\n",
    "\n",
    "\n",
    "#########################################\n",
    "##Rocchio\n",
    "print(\"######### Rocchio ########\")\n",
    "print(\"Training :: Rocchio Classifier...\")\n",
    "start_rocchio = time.time()\n",
    "\n",
    "##Training Rocchio\n",
    "with open('training.json', 'r') as training:\n",
    "    rocchio = RocchioClassifier(training, format = \"json\")\n",
    "stop_rocchio = time.time()\n",
    "\n",
    "print(\"Training Rocchio Classifier completed...\")\n",
    "elapsed_time_r = stop_rocchio - start_rocchio\n",
    "print(\"Recorded Training time (in seconds) = \" + str(elapsed_time_r))\n",
    "\n",
    "##Testing Rocchio\n",
    "print(\"Testing :: Rocchio Classifier...\")\n",
    "correct_pred_r = 0\n",
    "start_rocchio = time.time()\n",
    "\n",
    "for i in range(0, len(sentences)):\n",
    "    category = str(rocchio.classify(sentences[i])).lower()\n",
    "    expected = str(categories[i]).lower()\n",
    "    if category == expected:\n",
    "        correct_pred_r += 1\n",
    "        \n",
    "stop_rocchio = time.time()\n",
    "elapsed_time_r = stop_rocchio - start_rocchio\n",
    "\n",
    "print(\"Number of tests performed = \" + str(len(sentences)))\n",
    "print(\"Correct labels identified = \" + str(correct_pred_r))\n",
    "\n",
    "accuracy_r = correct_pred_r / len(sentences)\n",
    "print(\"Rocchio Classifier accuracy = \" + str(accuracy_r))\n",
    "print(\"Recorded Testing time (in seconds) = \" + str(elapsed_time_r))\n",
    "\n",
    "\n",
    "############################################\n",
    "##KNN\n",
    "print(\"######### KNN ########\")\n",
    "\n",
    "##Training KNN\n",
    "print(\"Training :: K-Nearest Neighbor Classifier...\")\n",
    "\n",
    "start_knn = time.time()\n",
    "with open('training.json', 'r') as training:\n",
    "    knn = KNNClassifier(training, format = \"json\")\n",
    "stop_knn = time.time()\n",
    "print(\"Training K-Nearest Neighbor Classifier completed...\")\n",
    "\n",
    "elapsed_time_k = stop_knn - start_knn\n",
    "print(\"Recorded Training time (in seconds) = \" + str(elapsed_time_k))\n",
    "\n",
    "##Testing KNN\n",
    "print(\"Testing :: K-Nearest Neighbor Classifier...\")\n",
    "correct_pred_K = 0\n",
    "start_knn = time.time()\n",
    "\n",
    "for i in range(0, len(sentences)):\n",
    "    category = str(nbc.classify(sentences[i])).lower()\n",
    "    expected = str(categories[i]).lower()\n",
    "    if category == expected:\n",
    "        correct_pred_K += 1\n",
    "stop_knn = time.time()\n",
    "\n",
    "elapsed_time_k = stop_knn - start_knn\n",
    "print(\"Number of tests performed = \" + str(len(sentences)))\n",
    "print(\"Correct labels identified = \" + str(correct_pred_K))\n",
    "\n",
    "accuracy = correct_pred_K / len(sentences)\n",
    "print(\"K-Nearest Neighbor Classifier accuracy = \" + str(accuracy))\n",
    "print(\" Recorded Testing time (in seconds): \" + str(elapsed_time_k))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
